<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Ordinary Least Sqaures vs. Gradient Descent â€” AIO: An I/Os guide to Data Science/AI</title>
	<meta name="description" content="Title: Ordinary Least Sqaures vs. Gradient Descent; Date: 2019-01-17; Author: N. Koenig">
	<meta name="author" content="N. Koenig">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
		<script src="/theme/html5.js"></script>
		<![endif]-->
	<link href="/theme/css/ipython.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="//maxcdn.bootstrapcdn.com/bootswatch/3.2.0/simplex/bootstrap.min.css" rel="stylesheet">
	<link href="/theme/css/local.css" rel="stylesheet">
	<link href="/theme/css/pygments.css" rel="stylesheet">
</head>
<body>
<div class="container">
	<div class="page-header">
		<h1><a href="/">AIO: An I/Os guide to Data Science/AI</a>
			<br>	</div>
	<div class="row">
		<div class="col-md-8 col-md-offset-2">
<div class="article" itemscope itemtype="http://schema.org/BlogPosting">
	<div class="text-center article-header">
		<h1 itemprop="name headline" class="article-title">Ordinary Least Sqaures vs. Gradient Descent</h1>
		<span itemprop="author" itemscope itemtype="http://schema.org/Person">
			<h4 itemprop="name">N. Koenig</h4>
		</span>
		<time datetime="2019-01-17T19:15:00-06:00" itemprop="datePublished">Thu 17 January 2019</time>
	</div>
	<div>
		Category:
		<span itemprop="articleSection">
			<a href="/category/python.html" rel="category">python</a>
		</span>
	</div>
 
	<div>
		Tags:
		<span itemprop="keywords">
			<a href="/tag/data-science.html" rel="tag">Data Science</a>
		</span>
		<span itemprop="keywords">
			<a href="/tag/math.html" rel="tag">Math</a>
		</span>
		<span itemprop="keywords">
			<a href="/tag/python.html" rel="tag">Python</a>
		</span>
	</div>
	<div itemprop="articleBody" class="article-body"><style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style>
<style type="text/css">
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Two-Different-Ways-to-do-Regression?">Two Different Ways to do Regression?<a class="anchor-link" href="#Two-Different-Ways-to-do-Regression?">&#182;</a></h1><p>Remember in graduate school when we learned about gradient descent as it applied to factor analysis (Principal Compenents Analysis) and SEM? Your professor drew something like this on the board:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s1">&#39;Images/gradient2.png&#39;</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[2]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-idea-of-local-minima's-and-the-global-minima,-etc.-For-some-reason-I-was-never-told-this-is-one-method-for-linear-regression-too.">The idea of local minima's and the global minima, etc. For some reason I was never told this is one method for linear regression too.<a class="anchor-link" href="#The-idea-of-local-minima's-and-the-global-minima,-etc.-For-some-reason-I-was-never-told-this-is-one-method-for-linear-regression-too.">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Ordinary-Least-Squares-(OLS)">Ordinary Least Squares (OLS)<a class="anchor-link" href="#Ordinary-Least-Squares-(OLS)">&#182;</a></h1><p>Despite what your professors told you about the Church of OLS.</p>
<p>OLS is actually a very specific formula that turns the regression problem into what's known in math as <strong>close-formed solution</strong></p>
<p><strong>$\beta=(X'X)^{-1}X'Y$</strong></p>
<p>This is the actual formula, you essentially invert the matrix and can solve for the <strong>"global minimum"</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="End-of-story.....right!">End of story.....right!<a class="anchor-link" href="#End-of-story.....right!">&#182;</a></h2><p>In our work this isn't very computationally expensive as the # of variables in most of our models are extremely reasonable for computational purposes. But if you had 1,000+ variables in your model the computation would begin to become much more complex. In these instances gradient descent is necessary.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Remember-when-people-talk-about-the-importance-of-standardization-or-normalitation?">Remember when people talk about the importance of standardization or normalitation?<a class="anchor-link" href="#Remember-when-people-talk-about-the-importance-of-standardization-or-normalitation?">&#182;</a></h4><p>The truth is that when it comes to OLS it's irrelevant, the formula is just as easy to solve if the numbers are 1,000,000,000 as they are if they are if it's 1.0. But if you are using gradient descent those numbers make a huge differenece.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Gradient-Descent">Gradient Descent<a class="anchor-link" href="#Gradient-Descent">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># continue talking about GD &amp; OLS</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/train.csv&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[7]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>crim</th>
      <th>zn</th>
      <th>indus</th>
      <th>chas</th>
      <th>nox</th>
      <th>rm</th>
      <th>age</th>
      <th>dis</th>
      <th>rad</th>
      <th>tax</th>
      <th>ptratio</th>
      <th>black</th>
      <th>lstat</th>
      <th>medv</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1</td>
      <td>296</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2</td>
      <td>242</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3</td>
      <td>222</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7</td>
      <td>0.08829</td>
      <td>12.5</td>
      <td>7.87</td>
      <td>0</td>
      <td>0.524</td>
      <td>6.012</td>
      <td>66.6</td>
      <td>5.5605</td>
      <td>5</td>
      <td>311</td>
      <td>15.2</td>
      <td>395.60</td>
      <td>12.43</td>
      <td>22.9</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The Torch backend works well with numpy, so in order to get a numpy array out of a pandas dataframe we can just use the .values method at the end. You can see that the type for X is now a numpy.ndarray.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;While in a dataframe we get the following type; &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ID&#39;</span><span class="p">,</span><span class="s1">&#39;black&#39;</span><span class="p">,</span><span class="s1">&#39;medv&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After extracting just the values we now get; &quot;</span><span class="p">,(</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>While in a dataframe we get the following type;  &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
After extracting just the values we now get;  &lt;class &#39;numpy.ndarray&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matrix-Shape">Matrix Shape<a class="anchor-link" href="#Matrix-Shape">&#182;</a></h2><p>Now let's examine the shape. Torch needs a 2d-array, let's ensure our X and y variables are both 2-d.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> 
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(333, 12)
(333,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are good on the X matrix, but you can see that the y matrix has a shape of (333,) we need to turn that into (333,1). So let's reshape it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[25]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(333, 1)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another important thing we discussed earlier was that when using gradient descent variables that are on very different scales like tax and room can lead to vanishing gradients. By examining each variable below we can clearly see they are on a very different scale.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;tax&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>count    333.000000
mean     409.279279
std      170.841988
min      188.000000
25%      279.000000
50%      330.000000
75%      666.000000
max      711.000000
Name: tax, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;rm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[30]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>count    333.000000
mean       6.265619
std        0.703952
min        3.561000
25%        5.884000
50%        6.202000
75%        6.595000
max        8.725000
Name: rm, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What we will have to do is re-scale it. In our methods courses that was commonly referred to as converting it to a <strong>Z-score</strong>. In statistics and machine learning they common refer to it as standardizing the data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In <strong>Numpy</strong> you will need to use indexing, I'll show you how it works quickly, so we can see what the means and standard deviations look like after standardizing.</p>
<ol>
<li>First we call the variable, in the case of our X matrix above, the variable itself is X</li>
<li>Second we provide brackets after the X</li>
<li>Third we can place 2 values inside the brackets, because our matrix is 2-d. The first will identify the row and the second the column.</li>
</ol>
<p>So if we wanted to look at the first row and first column which would refer to the crime column (remember we dropped ID) we would write this:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[47]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># note indexing in python starts with zero</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[47]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.00632</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you look at the <strong>dataframe</strong> above you will see that the value matches.</p>
<p>If we then wanted to look at every response for a given column we could just use X[:,0]</p>
<p>Now, let's standardize the data and look at the mean and standard deviation for the <strong>rm</strong> column.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[54]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">preprocessing</span>

<span class="n">standard_scalar</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_standard</span> <span class="o">=</span> <span class="n">standard_scalar</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_standard</span> <span class="o">=</span> <span class="n">standard_scalar</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's get the new mean and standard deviation for the <strong>rm</strong> column now.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mean for standardized rm; &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">[:,</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Standard Deviation for standardized rm; &#39;</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">[:,</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mean for standardized rm;  0.0
Standard Deviation for standardized rm;  1.0
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see after applying the standard scalar class we now have a mean of 0 and a standard deviation of 1 for rm and for all other variables.</p>
<p>Since I am learning PyTorch we will be using that for our gradient descent example</p>
<h1 id="PyTorch">PyTorch<a class="anchor-link" href="#PyTorch">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span> <span class="c1"># import the packages</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>PyTorch works best with the arrays in datatype float32, so let's ensure the matrices are in that datatype</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_standard</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_standard</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y_standard</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_standard</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below we will be creating the class, this is similar to what is already created for you in scikit learn and most other libraries, but the code is pretty much plug and play</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Create class</span>
<span class="k">class</span> <span class="nc">LinearRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearRegressionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>  
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we are going to instantiate the class by adding the input and output dimensions. If we remember which we can get from the second column in the 2-day arrays shapes we looked at earlier. Which happen to be 12 and 1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegressionModel</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we instantiate the loss class, this is what gradient descent will be attempting to minimize.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After that we instantiate the optimization algorithm and define the learning rate, which is essentially how large of steps it will take during gradient descent.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[86]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># Convert numpy array to torch Variable</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_standard</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_standard</span><span class="p">)</span>

    <span class="c1"># Clear gradients w.r.t. parameters</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> 
    
    <span class="c1"># Forward to get output</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    
    <span class="c1"># Calculate Loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    
    <span class="c1"># Getting gradients w.r.t. parameters</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># Updating parameters</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;epoch </span><span class="si">{}</span><span class="s1">, loss </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 1, loss 1.7567135095596313
epoch 2, loss 1.6154037714004517
epoch 3, loss 1.498350977897644
epoch 4, loss 1.4004356861114502
epoch 5, loss 1.317673921585083
epoch 6, loss 1.2469617128372192
epoch 7, loss 1.1858789920806885
epoch 8, loss 1.132535696029663
epoch 9, loss 1.085453987121582
epoch 10, loss 1.0434762239456177
epoch 11, loss 1.0056928396224976
epoch 12, loss 0.9713881611824036
epoch 13, loss 0.9399966597557068
epoch 14, loss 0.9110700488090515
epoch 15, loss 0.8842512369155884
epoch 16, loss 0.8592543601989746
epoch 17, loss 0.8358493447303772
epoch 18, loss 0.8138494491577148
epoch 19, loss 0.7931022047996521
epoch 20, loss 0.7734819650650024
epoch 21, loss 0.7548843026161194
epoch 22, loss 0.737221360206604
epoch 23, loss 0.7204188704490662
epoch 24, loss 0.7044129371643066
epoch 25, loss 0.6891481876373291
epoch 26, loss 0.6745762825012207
epoch 27, loss 0.6606543660163879
epoch 28, loss 0.647344172000885
epoch 29, loss 0.6346112489700317
epoch 30, loss 0.622424304485321
epoch 31, loss 0.610754668712616
epoch 32, loss 0.5995760560035706
epoch 33, loss 0.5888639092445374
epoch 34, loss 0.5785956382751465
epoch 35, loss 0.5687499642372131
epoch 36, loss 0.5593070387840271
epoch 37, loss 0.5502480864524841
epoch 38, loss 0.5415555238723755
epoch 39, loss 0.5332126021385193
epoch 40, loss 0.5252036452293396
epoch 41, loss 0.517513632774353
epoch 42, loss 0.5101284384727478
epoch 43, loss 0.5030344724655151
epoch 44, loss 0.49621903896331787
epoch 45, loss 0.48966988921165466
epoch 46, loss 0.4833754003047943
epoch 47, loss 0.47732454538345337
epoch 48, loss 0.4715067744255066
epoch 49, loss 0.46591201424598694
epoch 50, loss 0.46053072810173035
epoch 51, loss 0.4553537666797638
epoch 52, loss 0.4503723978996277
epoch 53, loss 0.44557827711105347
epoch 54, loss 0.4409635365009308
epoch 55, loss 0.4365205764770508
epoch 56, loss 0.43224209547042847
epoch 57, loss 0.4281212389469147
epoch 58, loss 0.42415139079093933
epoch 59, loss 0.42032626271247864
epoch 60, loss 0.4166398048400879
epoch 61, loss 0.41308629512786865
epoch 62, loss 0.4096601903438568
epoch 63, loss 0.4063562750816345
epoch 64, loss 0.40316951274871826
epoch 65, loss 0.4000951051712036
epoch 66, loss 0.39712846279144287
epoch 67, loss 0.39426520466804504
epoch 68, loss 0.39150112867355347
epoch 69, loss 0.3888322114944458
epoch 70, loss 0.3862546384334564
epoch 71, loss 0.38376474380493164
epoch 72, loss 0.3813589811325073
epoch 73, loss 0.3790340721607208
epoch 74, loss 0.3767867088317871
epoch 75, loss 0.374613881111145
epoch 76, loss 0.3725126087665558
epoch 77, loss 0.37048012018203735
epoch 78, loss 0.36851367354393005
epoch 79, loss 0.36661073565483093
epoch 80, loss 0.3647688031196594
epoch 81, loss 0.3629855215549469
epoch 82, loss 0.3612586557865143
epoch 83, loss 0.3595859706401825
epoch 84, loss 0.35796546936035156
epoch 85, loss 0.35639509558677673
epoch 86, loss 0.35487300157546997
epoch 87, loss 0.35339730978012085
epoch 88, loss 0.3519662916660309
epoch 89, loss 0.35057830810546875
epoch 90, loss 0.34923169016838074
epoch 91, loss 0.3479249179363251
epoch 92, loss 0.34665653109550476
epoch 93, loss 0.3454250991344452
epoch 94, loss 0.3442292809486389
epoch 95, loss 0.3430677652359009
epoch 96, loss 0.3419392704963684
epoch 97, loss 0.34084266424179077
epoch 98, loss 0.33977675437927246
epoch 99, loss 0.33874043822288513
epoch 100, loss 0.3377326726913452
epoch 101, loss 0.33675241470336914
epoch 102, loss 0.3357987403869629
epoch 103, loss 0.33487066626548767
epoch 104, loss 0.33396729826927185
epoch 105, loss 0.33308783173561096
epoch 106, loss 0.3322313725948334
epoch 107, loss 0.331397145986557
epoch 108, loss 0.33058440685272217
epoch 109, loss 0.3297923803329468
epoch 110, loss 0.3290203809738159
epoch 111, loss 0.32826775312423706
epoch 112, loss 0.3275338411331177
epoch 113, loss 0.32681795954704285
epoch 114, loss 0.326119601726532
epoch 115, loss 0.32543808221817017
epoch 116, loss 0.3247729539871216
epoch 117, loss 0.3241235911846161
epoch 118, loss 0.32348954677581787
epoch 119, loss 0.32287028431892395
epoch 120, loss 0.3222653269767761
epoch 121, loss 0.3216742277145386
epoch 122, loss 0.3210965692996979
epoch 123, loss 0.3205319046974182
epoch 124, loss 0.31997978687286377
epoch 125, loss 0.3194398880004883
epoch 126, loss 0.3189118206501007
epoch 127, loss 0.3183951675891876
epoch 128, loss 0.31788963079452515
epoch 129, loss 0.31739482283592224
epoch 130, loss 0.3169104754924774
epoch 131, loss 0.31643620133399963
epoch 132, loss 0.3159717917442322
epoch 133, loss 0.315516859292984
epoch 134, loss 0.3150711953639984
epoch 135, loss 0.3146345019340515
epoch 136, loss 0.31420648097991943
epoch 137, loss 0.31378695368766785
epoch 138, loss 0.3133755922317505
epoch 139, loss 0.3129722476005554
epoch 140, loss 0.31257662177085876
epoch 141, loss 0.3121885359287262
epoch 142, loss 0.311807781457901
epoch 143, loss 0.3114341199398041
epoch 144, loss 0.3110673725605011
epoch 145, loss 0.31070736050605774
epoch 146, loss 0.3103539049625397
epoch 147, loss 0.3100067973136902
epoch 148, loss 0.30966588854789734
epoch 149, loss 0.3093309998512268
epoch 150, loss 0.30900198221206665
epoch 151, loss 0.3086787164211273
epoch 152, loss 0.3083609640598297
epoch 153, loss 0.30804866552352905
epoch 154, loss 0.307741641998291
epoch 155, loss 0.30743974447250366
epoch 156, loss 0.30714288353919983
epoch 157, loss 0.3068509101867676
epoch 158, loss 0.30656367540359497
epoch 159, loss 0.30628111958503723
epoch 160, loss 0.30600306391716003
epoch 161, loss 0.3057294487953186
epoch 162, loss 0.3054601550102234
epoch 163, loss 0.30519506335258484
epoch 164, loss 0.3049340844154358
epoch 165, loss 0.3046770989894867
epoch 166, loss 0.30442407727241516
epoch 167, loss 0.3041748106479645
epoch 168, loss 0.30392932891845703
epoch 169, loss 0.3036874830722809
epoch 170, loss 0.30344921350479126
epoch 171, loss 0.3032144010066986
epoch 172, loss 0.30298301577568054
epoch 173, loss 0.3027549684047699
epoch 174, loss 0.3025301396846771
epoch 175, loss 0.3023085296154022
epoch 176, loss 0.30209001898765564
epoch 177, loss 0.301874577999115
epoch 178, loss 0.3016620874404907
epoch 179, loss 0.30145254731178284
epoch 180, loss 0.3012458384037018
epoch 181, loss 0.30104193091392517
epoch 182, loss 0.30084073543548584
epoch 183, loss 0.3006422817707062
epoch 184, loss 0.30044639110565186
epoch 185, loss 0.30025309324264526
epoch 186, loss 0.3000623285770416
epoch 187, loss 0.2998740077018738
epoch 188, loss 0.2996881306171417
epoch 189, loss 0.2995046079158783
epoch 190, loss 0.2993234395980835
epoch 191, loss 0.2991445064544678
epoch 192, loss 0.2989678382873535
epoch 193, loss 0.29879334568977356
epoch 194, loss 0.2986209988594055
epoch 195, loss 0.2984507977962494
epoch 196, loss 0.2982826232910156
epoch 197, loss 0.2981165051460266
epoch 198, loss 0.2979523837566376
epoch 199, loss 0.29779019951820374
epoch 200, loss 0.2976299524307251
epoch 201, loss 0.2974715828895569
epoch 202, loss 0.2973150610923767
epoch 203, loss 0.29716038703918457
epoch 204, loss 0.2970074713230133
epoch 205, loss 0.2968563139438629
epoch 206, loss 0.296706885099411
epoch 207, loss 0.2965591549873352
epoch 208, loss 0.2964130938053131
epoch 209, loss 0.29626867175102234
epoch 210, loss 0.2961258590221405
epoch 211, loss 0.2959846258163452
epoch 212, loss 0.2958449423313141
epoch 213, loss 0.29570677876472473
epoch 214, loss 0.29557013511657715
epoch 215, loss 0.29543498158454895
epoch 216, loss 0.29530125856399536
epoch 217, loss 0.29516899585723877
epoch 218, loss 0.2950381338596344
epoch 219, loss 0.29490864276885986
epoch 220, loss 0.29478052258491516
epoch 221, loss 0.2946537733078003
epoch 222, loss 0.2945283055305481
epoch 223, loss 0.29440414905548096
epoch 224, loss 0.2942813038825989
epoch 225, loss 0.2941596806049347
epoch 226, loss 0.2940393388271332
epoch 227, loss 0.2939201891422272
epoch 228, loss 0.29380226135253906
epoch 229, loss 0.29368552565574646
epoch 230, loss 0.293569952249527
epoch 231, loss 0.2934555411338806
epoch 232, loss 0.293342262506485
epoch 233, loss 0.2932300865650177
epoch 234, loss 0.29311904311180115
epoch 235, loss 0.29300907254219055
epoch 236, loss 0.2929001450538635
epoch 237, loss 0.29279232025146484
epoch 238, loss 0.29268550872802734
epoch 239, loss 0.2925797402858734
epoch 240, loss 0.29247498512268066
epoch 241, loss 0.2923712134361267
epoch 242, loss 0.29226842522621155
epoch 243, loss 0.2921666204929352
epoch 244, loss 0.2920657694339752
epoch 245, loss 0.29196587204933167
epoch 246, loss 0.29186689853668213
epoch 247, loss 0.2917688190937042
epoch 248, loss 0.29167166352272034
epoch 249, loss 0.29157543182373047
epoch 250, loss 0.29148006439208984
epoch 251, loss 0.29138556122779846
epoch 252, loss 0.2912919223308563
epoch 253, loss 0.2911991477012634
epoch 254, loss 0.291107177734375
epoch 255, loss 0.2910160720348358
epoch 256, loss 0.2909257709980011
epoch 257, loss 0.29083627462387085
epoch 258, loss 0.2907475531101227
epoch 259, loss 0.290659636259079
epoch 260, loss 0.29057249426841736
epoch 261, loss 0.2904861271381378
epoch 262, loss 0.29040050506591797
epoch 263, loss 0.2903156280517578
epoch 264, loss 0.29023149609565735
epoch 265, loss 0.2901481091976166
epoch 266, loss 0.2900654375553131
epoch 267, loss 0.28998345136642456
epoch 268, loss 0.2899021804332733
epoch 269, loss 0.2898216247558594
epoch 270, loss 0.28974172472953796
epoch 271, loss 0.28966253995895386
epoch 272, loss 0.2895839810371399
epoch 273, loss 0.28950610756874084
epoch 274, loss 0.2894288897514343
epoch 275, loss 0.28935232758522034
epoch 276, loss 0.2892763912677765
epoch 277, loss 0.2892010807991028
epoch 278, loss 0.2891263961791992
epoch 279, loss 0.2890523374080658
epoch 280, loss 0.2889789044857025
epoch 281, loss 0.2889060378074646
epoch 282, loss 0.2888337969779968
epoch 283, loss 0.2887621223926544
epoch 284, loss 0.28869104385375977
epoch 285, loss 0.2886205315589905
epoch 286, loss 0.28855061531066895
epoch 287, loss 0.2884812355041504
epoch 288, loss 0.2884124219417572
epoch 289, loss 0.2883441746234894
epoch 290, loss 0.28827646374702454
epoch 291, loss 0.2882092595100403
epoch 292, loss 0.2881426215171814
epoch 293, loss 0.2880765199661255
epoch 294, loss 0.28801092505455017
epoch 295, loss 0.28794583678245544
epoch 296, loss 0.2878812849521637
epoch 297, loss 0.28781720995903015
epoch 298, loss 0.2877536416053772
epoch 299, loss 0.28769057989120483
epoch 300, loss 0.2876279950141907
epoch 301, loss 0.2875658869743347
epoch 302, loss 0.28750428557395935
epoch 303, loss 0.2874431312084198
epoch 304, loss 0.28738245368003845
epoch 305, loss 0.2873222231864929
epoch 306, loss 0.2872624695301056
epoch 307, loss 0.28720319271087646
epoch 308, loss 0.28714433312416077
epoch 309, loss 0.2870859205722809
epoch 310, loss 0.2870279550552368
epoch 311, loss 0.28697043657302856
epoch 312, loss 0.28691333532333374
epoch 313, loss 0.28685665130615234
epoch 314, loss 0.2868003845214844
epoch 315, loss 0.2867445647716522
epoch 316, loss 0.2866891324520111
epoch 317, loss 0.2866341173648834
epoch 318, loss 0.28657951951026917
epoch 319, loss 0.28652530908584595
epoch 320, loss 0.28647151589393616
epoch 321, loss 0.2864181101322174
epoch 322, loss 0.2863650918006897
epoch 323, loss 0.286312460899353
epoch 324, loss 0.286260187625885
epoch 325, loss 0.2862083315849304
epoch 326, loss 0.2861568033695221
epoch 327, loss 0.2861056923866272
epoch 328, loss 0.28605493903160095
epoch 329, loss 0.28600451350212097
epoch 330, loss 0.28595447540283203
epoch 331, loss 0.28590479493141174
epoch 332, loss 0.2858554720878601
epoch 333, loss 0.28580647706985474
epoch 334, loss 0.285757839679718
epoch 335, loss 0.28570955991744995
epoch 336, loss 0.28566160798072815
epoch 337, loss 0.285614013671875
epoch 338, loss 0.2855667173862457
epoch 339, loss 0.2855197787284851
epoch 340, loss 0.28547313809394836
epoch 341, loss 0.2854268550872803
epoch 342, loss 0.28538087010383606
epoch 343, loss 0.2853352129459381
epoch 344, loss 0.28528985381126404
epoch 345, loss 0.28524482250213623
epoch 346, loss 0.2852000892162323
epoch 347, loss 0.28515568375587463
epoch 348, loss 0.28511154651641846
epoch 349, loss 0.28506773710250854
epoch 350, loss 0.2850242257118225
epoch 351, loss 0.28498101234436035
epoch 352, loss 0.2849380671977997
epoch 353, loss 0.2848954498767853
epoch 354, loss 0.28485307097435
epoch 355, loss 0.28481101989746094
epoch 356, loss 0.2847692370414734
epoch 357, loss 0.28472772240638733
epoch 358, loss 0.28468647599220276
epoch 359, loss 0.28464552760124207
epoch 360, loss 0.28460484743118286
epoch 361, loss 0.28456443548202515
epoch 362, loss 0.28452426195144653
epoch 363, loss 0.2844843864440918
epoch 364, loss 0.28444477915763855
epoch 365, loss 0.2844054102897644
epoch 366, loss 0.28436630964279175
epoch 367, loss 0.2843274474143982
epoch 368, loss 0.28428885340690613
epoch 369, loss 0.28425049781799316
epoch 370, loss 0.2842124104499817
epoch 371, loss 0.2841745615005493
epoch 372, loss 0.28413695096969604
epoch 373, loss 0.2840995788574219
epoch 374, loss 0.2840624451637268
epoch 375, loss 0.2840255796909332
epoch 376, loss 0.28398892283439636
epoch 377, loss 0.2839525043964386
epoch 378, loss 0.28391632437705994
epoch 379, loss 0.283880352973938
epoch 380, loss 0.28384461998939514
epoch 381, loss 0.2838091254234314
epoch 382, loss 0.28377383947372437
epoch 383, loss 0.28373879194259644
epoch 384, loss 0.28370392322540283
epoch 385, loss 0.2836693227291107
epoch 386, loss 0.28363490104675293
epoch 387, loss 0.28360071778297424
epoch 388, loss 0.28356674313545227
epoch 389, loss 0.283532977104187
epoch 390, loss 0.28349941968917847
epoch 391, loss 0.28346607089042664
epoch 392, loss 0.2834329307079315
epoch 393, loss 0.2833999693393707
epoch 394, loss 0.28336724638938904
epoch 395, loss 0.2833347022533417
epoch 396, loss 0.283302366733551
epoch 397, loss 0.2832702100276947
epoch 398, loss 0.2832382917404175
epoch 399, loss 0.2832064926624298
epoch 400, loss 0.28317496180534363
epoch 401, loss 0.2831435799598694
epoch 402, loss 0.28311240673065186
epoch 403, loss 0.28308141231536865
epoch 404, loss 0.2830505967140198
epoch 405, loss 0.2830199599266052
epoch 406, loss 0.2829895317554474
epoch 407, loss 0.2829592525959015
epoch 408, loss 0.2829291820526123
epoch 409, loss 0.28289926052093506
epoch 410, loss 0.2828695476055145
epoch 411, loss 0.28283998370170593
epoch 412, loss 0.28281062841415405
epoch 413, loss 0.2827814221382141
epoch 414, loss 0.2827523946762085
epoch 415, loss 0.2827235162258148
epoch 416, loss 0.28269481658935547
epoch 417, loss 0.28266629576683044
epoch 418, loss 0.28263792395591736
epoch 419, loss 0.2826097309589386
epoch 420, loss 0.28258171677589417
epoch 421, loss 0.2825538218021393
epoch 422, loss 0.2825261056423187
epoch 423, loss 0.2824985682964325
epoch 424, loss 0.2824711799621582
epoch 425, loss 0.28244394063949585
epoch 426, loss 0.28241685032844543
epoch 427, loss 0.28238990902900696
epoch 428, loss 0.2823631465435028
epoch 429, loss 0.2823365330696106
epoch 430, loss 0.28231003880500793
epoch 431, loss 0.2822837233543396
epoch 432, loss 0.2822575569152832
epoch 433, loss 0.28223153948783875
epoch 434, loss 0.28220564126968384
epoch 435, loss 0.28217992186546326
epoch 436, loss 0.2821543216705322
epoch 437, loss 0.28212887048721313
epoch 438, loss 0.282103568315506
epoch 439, loss 0.2820783853530884
epoch 440, loss 0.2820533812046051
epoch 441, loss 0.282028466463089
epoch 442, loss 0.2820037305355072
epoch 443, loss 0.28197911381721497
epoch 444, loss 0.2819546163082123
epoch 445, loss 0.28193026781082153
epoch 446, loss 0.2819060683250427
epoch 447, loss 0.28188198804855347
epoch 448, loss 0.28185805678367615
epoch 449, loss 0.281834214925766
epoch 450, loss 0.2818105220794678
epoch 451, loss 0.2817869782447815
epoch 452, loss 0.2817635238170624
epoch 453, loss 0.2817402184009552
epoch 454, loss 0.2817170321941376
epoch 455, loss 0.2816939949989319
epoch 456, loss 0.28167104721069336
epoch 457, loss 0.2816482186317444
epoch 458, loss 0.28162553906440735
epoch 459, loss 0.28160297870635986
epoch 460, loss 0.28158053755760193
epoch 461, loss 0.28155818581581116
epoch 462, loss 0.2815359830856323
epoch 463, loss 0.28151386976242065
epoch 464, loss 0.2814919054508209
epoch 465, loss 0.28147003054618835
epoch 466, loss 0.28144827485084534
epoch 467, loss 0.28142663836479187
epoch 468, loss 0.28140512108802795
epoch 469, loss 0.2813837230205536
epoch 470, loss 0.2813624441623688
epoch 471, loss 0.28134122490882874
epoch 472, loss 0.28132015466690063
epoch 473, loss 0.2812991738319397
epoch 474, loss 0.2812783122062683
epoch 475, loss 0.2812575697898865
epoch 476, loss 0.2812369167804718
epoch 477, loss 0.2812163829803467
epoch 478, loss 0.2811959385871887
epoch 479, loss 0.2811756134033203
epoch 480, loss 0.28115537762641907
epoch 481, loss 0.2811352610588074
epoch 482, loss 0.28111523389816284
epoch 483, loss 0.2810952961444855
epoch 484, loss 0.28107547760009766
epoch 485, loss 0.281055748462677
epoch 486, loss 0.2810361385345459
epoch 487, loss 0.28101661801338196
epoch 488, loss 0.2809971868991852
epoch 489, loss 0.28097787499427795
epoch 490, loss 0.2809586226940155
epoch 491, loss 0.2809394896030426
epoch 492, loss 0.28092044591903687
epoch 493, loss 0.2809014916419983
epoch 494, loss 0.28088265657424927
epoch 495, loss 0.280863881111145
epoch 496, loss 0.2808452248573303
epoch 497, loss 0.2808266580104828
epoch 498, loss 0.28080815076828003
epoch 499, loss 0.2807897627353668
epoch 500, loss 0.2807714641094208
epoch 501, loss 0.2807532548904419
epoch 502, loss 0.2807351350784302
epoch 503, loss 0.28071707487106323
epoch 504, loss 0.28069913387298584
epoch 505, loss 0.2806812822818756
epoch 506, loss 0.28066349029541016
epoch 507, loss 0.28064581751823425
epoch 508, loss 0.2806282043457031
epoch 509, loss 0.28061068058013916
epoch 510, loss 0.28059324622154236
epoch 511, loss 0.2805759012699127
epoch 512, loss 0.28055861592292786
epoch 513, loss 0.28054141998291016
epoch 514, loss 0.280524343252182
epoch 515, loss 0.28050729632377625
epoch 516, loss 0.28049036860466003
epoch 517, loss 0.2804735004901886
epoch 518, loss 0.28045669198036194
epoch 519, loss 0.28044000267982483
epoch 520, loss 0.2804233729839325
epoch 521, loss 0.2804068326950073
epoch 522, loss 0.28039035201072693
epoch 523, loss 0.2803739607334137
epoch 524, loss 0.2803576588630676
epoch 525, loss 0.28034141659736633
epoch 526, loss 0.2803252339363098
epoch 527, loss 0.28030914068222046
epoch 528, loss 0.28029313683509827
epoch 529, loss 0.28027719259262085
epoch 530, loss 0.2802613079547882
epoch 531, loss 0.28024551272392273
epoch 532, loss 0.2802298069000244
epoch 533, loss 0.2802141606807709
epoch 534, loss 0.2801985740661621
epoch 535, loss 0.2801830768585205
epoch 536, loss 0.2801676392555237
epoch 537, loss 0.28015226125717163
epoch 538, loss 0.28013697266578674
epoch 539, loss 0.28012174367904663
epoch 540, loss 0.2801065742969513
epoch 541, loss 0.2800914943218231
epoch 542, loss 0.2800764739513397
epoch 543, loss 0.2800615131855011
epoch 544, loss 0.28004661202430725
epoch 545, loss 0.28003180027008057
epoch 546, loss 0.28001704812049866
epoch 547, loss 0.2800023555755615
epoch 548, loss 0.27998772263526917
epoch 549, loss 0.27997317910194397
epoch 550, loss 0.27995869517326355
epoch 551, loss 0.2799442708492279
epoch 552, loss 0.27992990612983704
epoch 553, loss 0.27991560101509094
epoch 554, loss 0.2799013555049896
epoch 555, loss 0.27988719940185547
epoch 556, loss 0.2798730731010437
epoch 557, loss 0.2798590362071991
epoch 558, loss 0.2798450291156769
epoch 559, loss 0.2798311114311218
epoch 560, loss 0.27981725335121155
epoch 561, loss 0.27980342507362366
epoch 562, loss 0.27978968620300293
epoch 563, loss 0.279776006937027
epoch 564, loss 0.2797623872756958
epoch 565, loss 0.279748797416687
epoch 566, loss 0.2797352969646454
epoch 567, loss 0.27972185611724854
epoch 568, loss 0.2797084450721741
epoch 569, loss 0.2796951234340668
epoch 570, loss 0.27968183159828186
epoch 571, loss 0.2796685993671417
epoch 572, loss 0.27965545654296875
epoch 573, loss 0.27964234352111816
epoch 574, loss 0.27962929010391235
epoch 575, loss 0.2796162962913513
epoch 576, loss 0.27960336208343506
epoch 577, loss 0.2795904576778412
epoch 578, loss 0.2795776128768921
epoch 579, loss 0.27956485748291016
epoch 580, loss 0.2795521020889282
epoch 581, loss 0.27953943610191345
epoch 582, loss 0.27952682971954346
epoch 583, loss 0.27951428294181824
epoch 584, loss 0.2795017659664154
epoch 585, loss 0.27948927879333496
epoch 586, loss 0.2794768810272217
epoch 587, loss 0.2794645130634308
epoch 588, loss 0.27945223450660706
epoch 589, loss 0.2794399559497833
epoch 590, loss 0.27942776679992676
epoch 591, loss 0.2794156074523926
epoch 592, loss 0.2794035077095032
epoch 593, loss 0.27939143776893616
epoch 594, loss 0.2793794572353363
epoch 595, loss 0.27936750650405884
epoch 596, loss 0.27935558557510376
epoch 597, loss 0.27934372425079346
epoch 598, loss 0.27933192253112793
epoch 599, loss 0.2793201506137848
epoch 600, loss 0.2793084681034088
epoch 601, loss 0.27929678559303284
epoch 602, loss 0.279285192489624
epoch 603, loss 0.2792735993862152
epoch 604, loss 0.27926206588745117
epoch 605, loss 0.2792505919933319
epoch 606, loss 0.2792391777038574
epoch 607, loss 0.2792277932167053
epoch 608, loss 0.2792164385318756
epoch 609, loss 0.27920517325401306
epoch 610, loss 0.2791939079761505
epoch 611, loss 0.27918270230293274
epoch 612, loss 0.27917155623435974
epoch 613, loss 0.27916043996810913
epoch 614, loss 0.2791493833065033
epoch 615, loss 0.27913835644721985
epoch 616, loss 0.2791273593902588
epoch 617, loss 0.2791164219379425
epoch 618, loss 0.279105544090271
epoch 619, loss 0.2790946960449219
epoch 620, loss 0.27908387780189514
epoch 621, loss 0.2790731191635132
epoch 622, loss 0.2790623903274536
epoch 623, loss 0.2790517210960388
epoch 624, loss 0.2790410816669464
epoch 625, loss 0.2790304720401764
epoch 626, loss 0.27901992201805115
epoch 627, loss 0.2790094017982483
epoch 628, loss 0.2789989411830902
epoch 629, loss 0.2789885103702545
epoch 630, loss 0.2789781093597412
epoch 631, loss 0.2789677679538727
epoch 632, loss 0.27895745635032654
epoch 633, loss 0.2789471745491028
epoch 634, loss 0.2789369523525238
epoch 635, loss 0.2789267599582672
epoch 636, loss 0.278916597366333
epoch 637, loss 0.2789064943790436
epoch 638, loss 0.27889642119407654
epoch 639, loss 0.2788863778114319
epoch 640, loss 0.2788763642311096
epoch 641, loss 0.27886641025543213
epoch 642, loss 0.278856486082077
epoch 643, loss 0.2788466215133667
epoch 644, loss 0.27883675694465637
epoch 645, loss 0.2788269519805908
epoch 646, loss 0.27881717681884766
epoch 647, loss 0.27880746126174927
epoch 648, loss 0.2787977457046509
epoch 649, loss 0.27878808975219727
epoch 650, loss 0.27877846360206604
epoch 651, loss 0.2787688970565796
epoch 652, loss 0.27875933051109314
epoch 653, loss 0.27874982357025146
epoch 654, loss 0.2787403166294098
epoch 655, loss 0.2787308990955353
epoch 656, loss 0.27872148156166077
epoch 657, loss 0.27871209383010864
epoch 658, loss 0.2787027657032013
epoch 659, loss 0.27869346737861633
epoch 660, loss 0.27868419885635376
epoch 661, loss 0.2786749601364136
epoch 662, loss 0.2786657512187958
epoch 663, loss 0.27865660190582275
epoch 664, loss 0.27864745259284973
epoch 665, loss 0.2786383628845215
epoch 666, loss 0.2786293029785156
epoch 667, loss 0.27862024307250977
epoch 668, loss 0.27861127257347107
epoch 669, loss 0.2786023020744324
epoch 670, loss 0.27859336137771606
epoch 671, loss 0.27858445048332214
epoch 672, loss 0.278575599193573
epoch 673, loss 0.27856677770614624
epoch 674, loss 0.2785579562187195
epoch 675, loss 0.2785491943359375
epoch 676, loss 0.2785404622554779
epoch 677, loss 0.2785317301750183
epoch 678, loss 0.2785230576992035
epoch 679, loss 0.27851441502571106
epoch 680, loss 0.2785058319568634
epoch 681, loss 0.27849721908569336
epoch 682, loss 0.2784886658191681
epoch 683, loss 0.2784801721572876
epoch 684, loss 0.2784716784954071
epoch 685, loss 0.278463214635849
epoch 686, loss 0.2784547805786133
epoch 687, loss 0.27844640612602234
epoch 688, loss 0.2784380316734314
epoch 689, loss 0.27842968702316284
epoch 690, loss 0.2784213721752167
epoch 691, loss 0.2784130871295929
epoch 692, loss 0.2784048616886139
epoch 693, loss 0.2783966362476349
epoch 694, loss 0.27838844060897827
epoch 695, loss 0.27838027477264404
epoch 696, loss 0.2783721387386322
epoch 697, loss 0.27836403250694275
epoch 698, loss 0.27835598587989807
epoch 699, loss 0.2783479392528534
epoch 700, loss 0.2783398926258087
epoch 701, loss 0.2783319056034088
epoch 702, loss 0.2783239781856537
epoch 703, loss 0.27831602096557617
epoch 704, loss 0.27830812335014343
epoch 705, loss 0.2783002555370331
epoch 706, loss 0.27829238772392273
epoch 707, loss 0.27828457951545715
epoch 708, loss 0.27827680110931396
epoch 709, loss 0.2782690227031708
epoch 710, loss 0.27826127409935
epoch 711, loss 0.27825355529785156
epoch 712, loss 0.2782458961009979
epoch 713, loss 0.2782382369041443
epoch 714, loss 0.27823057770729065
epoch 715, loss 0.2782229781150818
epoch 716, loss 0.2782154083251953
epoch 717, loss 0.27820783853530884
epoch 718, loss 0.27820032835006714
epoch 719, loss 0.27819281816482544
epoch 720, loss 0.2781853675842285
epoch 721, loss 0.2781778872013092
epoch 722, loss 0.27817046642303467
epoch 723, loss 0.2781630754470825
epoch 724, loss 0.27815571427345276
epoch 725, loss 0.278148353099823
epoch 726, loss 0.278141051530838
epoch 727, loss 0.278133749961853
epoch 728, loss 0.27812647819519043
epoch 729, loss 0.2781192362308502
epoch 730, loss 0.2781120240688324
epoch 731, loss 0.2781048119068146
epoch 732, loss 0.27809762954711914
epoch 733, loss 0.2780904769897461
epoch 734, loss 0.27808335423469543
epoch 735, loss 0.27807626128196716
epoch 736, loss 0.2780691683292389
epoch 737, loss 0.2780621349811554
epoch 738, loss 0.2780551016330719
epoch 739, loss 0.2780480980873108
epoch 740, loss 0.27804112434387207
epoch 741, loss 0.27803415060043335
epoch 742, loss 0.278027206659317
epoch 743, loss 0.27802029252052307
epoch 744, loss 0.2780134379863739
epoch 745, loss 0.27800655364990234
epoch 746, loss 0.2779996991157532
epoch 747, loss 0.2779929041862488
epoch 748, loss 0.2779861092567444
epoch 749, loss 0.27797931432724
epoch 750, loss 0.27797257900238037
epoch 751, loss 0.27796584367752075
epoch 752, loss 0.2779591381549835
epoch 753, loss 0.2779524624347687
epoch 754, loss 0.2779458165168762
epoch 755, loss 0.27793917059898376
epoch 756, loss 0.2779325544834137
epoch 757, loss 0.27792593836784363
epoch 758, loss 0.27791938185691833
epoch 759, loss 0.27791285514831543
epoch 760, loss 0.27790629863739014
epoch 761, loss 0.2778998017311096
epoch 762, loss 0.2778933048248291
epoch 763, loss 0.27788683772087097
epoch 764, loss 0.27788040041923523
epoch 765, loss 0.2778739631175995
epoch 766, loss 0.2778675854206085
epoch 767, loss 0.27786120772361755
epoch 768, loss 0.277854859828949
epoch 769, loss 0.277848482131958
epoch 770, loss 0.2778421938419342
epoch 771, loss 0.277835875749588
epoch 772, loss 0.2778296172618866
epoch 773, loss 0.2778233587741852
epoch 774, loss 0.27781713008880615
epoch 775, loss 0.2778109014034271
epoch 776, loss 0.27780473232269287
epoch 777, loss 0.27779853343963623
epoch 778, loss 0.27779239416122437
epoch 779, loss 0.2777862548828125
epoch 780, loss 0.277780145406723
epoch 781, loss 0.27777403593063354
epoch 782, loss 0.27776798605918884
epoch 783, loss 0.27776190638542175
epoch 784, loss 0.27775588631629944
epoch 785, loss 0.2777498662471771
epoch 786, loss 0.2777438759803772
epoch 787, loss 0.27773788571357727
epoch 788, loss 0.2777319550514221
epoch 789, loss 0.27772602438926697
epoch 790, loss 0.2777200937271118
epoch 791, loss 0.27771419286727905
epoch 792, loss 0.2777082920074463
epoch 793, loss 0.2777024507522583
epoch 794, loss 0.2776966094970703
epoch 795, loss 0.2776907682418823
epoch 796, loss 0.2776849567890167
epoch 797, loss 0.2776791751384735
epoch 798, loss 0.2776734232902527
epoch 799, loss 0.27766767144203186
epoch 800, loss 0.27766191959381104
epoch 801, loss 0.277656227350235
epoch 802, loss 0.27765050530433655
epoch 803, loss 0.2776448428630829
epoch 804, loss 0.2776391804218292
epoch 805, loss 0.27763354778289795
epoch 806, loss 0.2776279151439667
epoch 807, loss 0.2776223123073578
epoch 808, loss 0.2776167392730713
epoch 809, loss 0.2776111662387848
epoch 810, loss 0.2776055932044983
epoch 811, loss 0.27760007977485657
epoch 812, loss 0.27759456634521484
epoch 813, loss 0.2775890529155731
epoch 814, loss 0.2775835692882538
epoch 815, loss 0.27757811546325684
epoch 816, loss 0.2775726616382599
epoch 817, loss 0.2775672376155853
epoch 818, loss 0.27756181359291077
epoch 819, loss 0.2775564193725586
epoch 820, loss 0.2775510251522064
epoch 821, loss 0.27754566073417664
epoch 822, loss 0.27754032611846924
epoch 823, loss 0.27753502130508423
epoch 824, loss 0.27752968668937683
epoch 825, loss 0.2775244116783142
epoch 826, loss 0.2775191068649292
epoch 827, loss 0.27751386165618896
epoch 828, loss 0.27750861644744873
epoch 829, loss 0.2775033712387085
epoch 830, loss 0.27749815583229065
epoch 831, loss 0.2774929702281952
epoch 832, loss 0.27748778462409973
epoch 833, loss 0.27748262882232666
epoch 834, loss 0.2774774730205536
epoch 835, loss 0.2774723470211029
epoch 836, loss 0.2774672210216522
epoch 837, loss 0.2774621248245239
epoch 838, loss 0.27745702862739563
epoch 839, loss 0.2774519920349121
epoch 840, loss 0.2774469256401062
epoch 841, loss 0.2774418890476227
epoch 842, loss 0.27743685245513916
epoch 843, loss 0.277431845664978
epoch 844, loss 0.2774268686771393
epoch 845, loss 0.27742189168930054
epoch 846, loss 0.2774169147014618
epoch 847, loss 0.27741196751594543
epoch 848, loss 0.27740705013275146
epoch 849, loss 0.2774021327495575
epoch 850, loss 0.2773972451686859
epoch 851, loss 0.27739235758781433
epoch 852, loss 0.27738747000694275
epoch 853, loss 0.27738264203071594
epoch 854, loss 0.27737778425216675
epoch 855, loss 0.27737295627593994
epoch 856, loss 0.2773681581020355
epoch 857, loss 0.2773633599281311
epoch 858, loss 0.2773585617542267
epoch 859, loss 0.27735382318496704
epoch 860, loss 0.277349054813385
epoch 861, loss 0.27734431624412537
epoch 862, loss 0.2773396074771881
epoch 863, loss 0.27733489871025085
epoch 864, loss 0.2773301899433136
epoch 865, loss 0.27732551097869873
epoch 866, loss 0.27732086181640625
epoch 867, loss 0.27731621265411377
epoch 868, loss 0.2773115634918213
epoch 869, loss 0.2773069441318512
epoch 870, loss 0.2773023247718811
epoch 871, loss 0.2772977352142334
epoch 872, loss 0.2772931456565857
epoch 873, loss 0.2772885859012604
epoch 874, loss 0.27728405594825745
epoch 875, loss 0.27727949619293213
epoch 876, loss 0.2772749662399292
epoch 877, loss 0.27727046608924866
epoch 878, loss 0.2772659659385681
epoch 879, loss 0.27726149559020996
epoch 880, loss 0.2772569954395294
epoch 881, loss 0.27725255489349365
epoch 882, loss 0.2772481143474579
epoch 883, loss 0.2772436738014221
epoch 884, loss 0.27723926305770874
epoch 885, loss 0.27723485231399536
epoch 886, loss 0.27723047137260437
epoch 887, loss 0.2772260904312134
epoch 888, loss 0.2772217392921448
epoch 889, loss 0.2772173583507538
epoch 890, loss 0.27721306681632996
epoch 891, loss 0.27720871567726135
epoch 892, loss 0.27720439434051514
epoch 893, loss 0.2772001028060913
epoch 894, loss 0.2771958112716675
epoch 895, loss 0.27719154953956604
epoch 896, loss 0.2771872878074646
epoch 897, loss 0.27718305587768555
epoch 898, loss 0.2771787941455841
epoch 899, loss 0.27717456221580505
epoch 900, loss 0.2771703600883484
epoch 901, loss 0.2771661579608917
epoch 902, loss 0.27716198563575745
epoch 903, loss 0.27715781331062317
epoch 904, loss 0.2771536707878113
epoch 905, loss 0.277149498462677
epoch 906, loss 0.2771453857421875
epoch 907, loss 0.2771412432193756
epoch 908, loss 0.2771371304988861
epoch 909, loss 0.277133047580719
epoch 910, loss 0.2771289646625519
epoch 911, loss 0.27712488174438477
epoch 912, loss 0.27712079882621765
epoch 913, loss 0.2771167755126953
epoch 914, loss 0.2771127223968506
epoch 915, loss 0.27710869908332825
epoch 916, loss 0.2771046757698059
epoch 917, loss 0.27710068225860596
epoch 918, loss 0.2770967185497284
epoch 919, loss 0.27709272503852844
epoch 920, loss 0.2770887613296509
epoch 921, loss 0.2770847976207733
epoch 922, loss 0.27708086371421814
epoch 923, loss 0.27707692980766296
epoch 924, loss 0.2770729959011078
epoch 925, loss 0.277069091796875
epoch 926, loss 0.2770651876926422
epoch 927, loss 0.2770613133907318
epoch 928, loss 0.2770574390888214
epoch 929, loss 0.2770535945892334
epoch 930, loss 0.277049720287323
epoch 931, loss 0.277045875787735
epoch 932, loss 0.27704206109046936
epoch 933, loss 0.27703824639320374
epoch 934, loss 0.2770344316959381
epoch 935, loss 0.2770306468009949
epoch 936, loss 0.27702686190605164
epoch 937, loss 0.2770230770111084
epoch 938, loss 0.27701932191848755
epoch 939, loss 0.2770155668258667
epoch 940, loss 0.27701184153556824
epoch 941, loss 0.2770081162452698
epoch 942, loss 0.2770043909549713
epoch 943, loss 0.27700066566467285
epoch 944, loss 0.27699699997901917
epoch 945, loss 0.2769933044910431
epoch 946, loss 0.2769896388053894
epoch 947, loss 0.2769859731197357
epoch 948, loss 0.27698230743408203
epoch 949, loss 0.27697867155075073
epoch 950, loss 0.27697503566741943
epoch 951, loss 0.27697139978408813
epoch 952, loss 0.2769678235054016
epoch 953, loss 0.2769642174243927
epoch 954, loss 0.2769606113433838
epoch 955, loss 0.27695703506469727
epoch 956, loss 0.27695345878601074
epoch 957, loss 0.2769499123096466
epoch 958, loss 0.27694636583328247
epoch 959, loss 0.27694281935691833
epoch 960, loss 0.2769393026828766
epoch 961, loss 0.27693578600883484
epoch 962, loss 0.2769322693347931
epoch 963, loss 0.27692878246307373
epoch 964, loss 0.27692529559135437
epoch 965, loss 0.276921808719635
epoch 966, loss 0.27691835165023804
epoch 967, loss 0.2769148647785187
epoch 968, loss 0.2769114375114441
epoch 969, loss 0.2769080102443695
epoch 970, loss 0.2769045829772949
epoch 971, loss 0.27690115571022034
epoch 972, loss 0.27689775824546814
epoch 973, loss 0.27689436078071594
epoch 974, loss 0.27689096331596375
epoch 975, loss 0.27688759565353394
epoch 976, loss 0.2768842279911041
epoch 977, loss 0.2768808603286743
epoch 978, loss 0.2768775224685669
epoch 979, loss 0.2768741846084595
epoch 980, loss 0.27687084674835205
epoch 981, loss 0.276867538690567
epoch 982, loss 0.276864230632782
epoch 983, loss 0.27686092257499695
epoch 984, loss 0.2768576145172119
epoch 985, loss 0.27685433626174927
epoch 986, loss 0.276851087808609
epoch 987, loss 0.27684780955314636
epoch 988, loss 0.2768445611000061
epoch 989, loss 0.27684131264686584
epoch 990, loss 0.276838093996048
epoch 991, loss 0.2768348753452301
epoch 992, loss 0.27683162689208984
epoch 993, loss 0.27682843804359436
epoch 994, loss 0.2768252491950989
epoch 995, loss 0.2768220603466034
epoch 996, loss 0.2768188714981079
epoch 997, loss 0.2768157124519348
epoch 998, loss 0.2768125534057617
epoch 999, loss 0.2768093943595886
epoch 1000, loss 0.2768062651157379
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see after <strong>1000 epochs we have an MSE loss of 0.2768</strong></p>
<p>Now let's see what OLS comes up with.</p>
<h1 id="OLS">OLS<a class="anchor-link" href="#OLS">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LinearRegression</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_standard</span><span class="p">,</span><span class="n">y_standard</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[87]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[89]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sklearn_preds</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_standard</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="k">import</span> <span class="n">metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Scikit Learn MSE:&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_standard</span><span class="p">,</span> <span class="n">sklearn_preds</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Scikit Learn MSE: 0.2756602
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="As-you-can-see-after-about-1000-epochs-in-gradient-descent-the-Mean-Squared-Error-is-extremely-close-to-the-mean-squared-error-obtained-from-the-OLS-close-formed-solution.">As you can see after about 1000 epochs in gradient descent the Mean Squared Error is extremely close to the mean squared error obtained from the OLS close-formed solution.<a class="anchor-link" href="#As-you-can-see-after-about-1000-epochs-in-gradient-descent-the-Mean-Squared-Error-is-extremely-close-to-the-mean-squared-error-obtained-from-the-OLS-close-formed-solution.">&#182;</a></h3>
</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</div>
	<hr>
	<h2>Comments</h2>
<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'https-nkoenig06-github-io'; 
    var disqus_title = 'Ordinary Least Sqaures vs. Gradient Descent';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
		</div>
	</div> 	<!-- <hr> -->
</div> <!-- /container -->
<footer class="aw-footer bg-danger">
	<div class="container"> <!-- footer -->
		<div class="row">
			<div class="col-md-10 col-md-offset-1">
				<div class="row">
					<div class="col-md-3">
						<h4>Navigation</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="">AIO: An I/Os guide to Data Science/AI</a></li>
							<li><a href="/feeds/all.atom.xml" type="application/atom+xml"><i class="fa fa-rss "></i> atom</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Author</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="http://twitter.com/N_KNIG/">Twitter</a></li>
							<li><a href="http://www.linkedin.com/in/nick-koenig-69699a27/">LinkedIn</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Categories</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="/category/about/site.html">about/site (2)</a></li>
							<li><a href="/category/machine-learning.html">machine learning (1)</a></li>
							<li><a href="/category/programming.html">programming (1)</a></li>
							<li><a href="/category/python.html">python (2)</a></li>
							<li><a href="/category/r.html">R (1)</a></li>
						</ul>
					</div>
					<div class="col-md-3">
						<h4>Links</h4>
						<ul class="list-unstyled my-list-style">
							<li><a href="http://jupyter.org/">Jupyter.org</a></li>
							<li><a href="http://python.org/">Python.org</a></li>
							<li><a href="http://kdnuggets.com/">KDnuggets</a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>
</footer>
<div class="container">
	<div class="row">
		<div class="col-md-12 text-center center-block aw-bottom">
			<p>&copy; N. Koenig 2016</p>
			<p>Powered by Pelican</p>
		</div>
	</div>
</div>
<!-- JavaScript -->
<script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script type="text/javascript">
jQuery(document).ready(function($) {
	$("div.collapseheader").click(function () {
		$header = $(this).children("span").first();
		$codearea = $(this).children(".input_area");
		$codearea.slideToggle(500, function () {
			$header.text(function () {
				return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
			});
		});
	});
});
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-132815257-1', 'auto');
  ga('send', 'pageview');

</script>
<a href="https://github.com/NKoenig06"><img style="position: absolute; top: 40px; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png" alt="Fork me on GitHub" /></a>
</body>
</html>